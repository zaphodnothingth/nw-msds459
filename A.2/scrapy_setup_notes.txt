""" process notes
    refs: 
        https://www.pluralsight.com/guides/web-scraping-with-scrapy
        https://const.fr/blog/tech/scrapy-how-to-crawl-pages/
        https://doc.scrapy.org/en/0.12/intro/tutorial.html
        https://www.jitsejan.com/scraping-with-scrapy-and-postgres

"""

# setup a project: 
$ scrapy startproject tesla

# define items to be collected in crawl
    # make start_urls in spiders/spider_competitors.py read from jsonl
    



# run competitor spider
scrapy crawl competitors -o data_out/competitors_scrap_result_2deep.jsonl -t jsonlines
# run wiki spider
scrapy crawl wikip -o data_out/wikip_scrape_result.jsonl -t jsonlines

# use pgadmin?  watch lecture 11min in
